+++
title = "Research"
date = "2014-04-09"
aliases = ["work","research","publications"]
+++

## ***Kinect VR Rehabilitation/Exercise System***

**Status:** In-Progress

**Description:** Research Project to integreate a Kinect 2 Sensor with a VR Headset to give the user realtime feedback on excercise posture using `Fast Dynamic Time Warping` to compare the user pose to that of a professional. The Goal of this project is to validate the use of such a system for remote rehabilitation uses. 

---

## ***Mobile, Egocentric Human Body Motion Reconstruction Using Only Eyeglasses-mounted Cameras and a Few Body-worn Inertial Sensors***

**Status:** Accepted to IEEEVR2021

**Abstract:** We envision a convenient telepresence system available to users
anywhere, anytime. Such a system requires displays and sensors embedded in commonly worn items such as eyeglasses, wristwatches,
and shoes. To that end, we present a standalone real-time system for
the dynamic 3D capture of a person, relying only on cameras embedded into a head-worn device, and on Inertial Measurement Units
(IMUs) worn on the wrists and ankles. Our prototype system egocentrically reconstructs the wearerâ€™s motion via learning-based pose
estimation, which fuses inputs from visual and inertial sensors that
complement each other, overcoming challenges such as inconsistent
limb visibility in head-worn views, as well as pose ambiguity from
sparse IMUs. The estimated pose is continuously re-targeted to a
prescanned surface model, resulting in a high-fidelity 3D reconstruction. We demonstrate our system by reconstructing various human
body movements and show that our visual-inertial learning-based
method, which runs in real time, outperforms both visual-only and
inertial-only approaches. We captured an egocentric visual-inertial
3D human pose dataset, which we plan to make publicly available
for training and evaluating similar methods.

![](/img/research/ego-out.PNG)

--- 

## ***Project North Star***

**Status:** On-Hold

**Description:** The goal of this project was to build an opensource AR headset with a 90 degree FOV and augment it with 6 Degrees of Freedom to test how wider FOV could be levraged in AR training excercises. 

--- 

## ***Data-driven modeling of group entitativity in virtual environments***
**Status:** Accepted at CPVR 2018

**Abstract:** We present a data-driven algorithm to model and predict the socio-emotional impact of groups on observers. Psychological research finds that highly entitative ie cohesive and uniform groups induce threat and unease in observers. Our algorithm models realistic trajectory-level behaviors to classify and map the motion-based entitativity of crowds. This mapping is based on a statistical scheme that dynamically learns pedestrian behavior and computes the resultant entitativity induced emotion through group motion characteristics. We also present a novel interactive multi-agent simulation algorithm to model entitative groups and conduct a VR user study to validate the socio-emotional predictive power of our algorithm. We further show that model-generated high-entitativity groups do induce more negative emotions than low-entitative groups.

![](/img/research/enti.PNG)
